{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from modules.preamble import *\n",
    "import json\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skfuzzy import cmeans\n",
    "\n",
    "from modules.PFS import PFS_layer, PFS_CP\n",
    "from modules.kappa import *\n",
    "from modules.RNN_utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data\n",
    "df_train = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/df_train.hdf'))\n",
    "df_val = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/df_val.hdf'))\n",
    "df_test = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/df_test.hdf'))\n",
    "\n",
    "X_train = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/X_train.hdf')).values\n",
    "X_val = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/X_val.hdf')).values\n",
    "X_test = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/X_test.hdf')).values\n",
    "\n",
    "y_train = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/y_train.hdf')).values.ravel() #flat\n",
    "y_val = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/y_val.hdf')).values.ravel()\n",
    "y_test = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/y_test.hdf')).values.ravel()\n",
    "\n",
    "instance_weights_train = pd.read_hdf(os.path.join(data_base_path, 'modeling_data/instance_weights_train.hdf')).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment w.r.t. class weight\n",
    "Must (awkwardly) pass these as aggregated instance + class weights (multiply them) to tensorflow. Default interface offers no option to apply instance + class weights during training and only sample weights during testing (i.e. not possible when passing both arguments \"class_weight\" and \"sample_weight\"). Tested this awkward aspect extensively due to weird first results - pretty sure TF does not offer the feature we need out-of-the-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust sample weight in training w.r.t classes (i.e. multiply by class weight).\n",
    "\n",
    "class_weights = compute_class_weight('balanced', [0,1], y_train) #Class weights as array\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]} #Convert to dictionary\n",
    "\n",
    "instance_class_weights_train = np.array(\n",
    "    [sample_weight * class_weights[y] for sample_weight, y in zip(instance_weights_train, y_train)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(688457, 31) (117419, 31) (118967, 31)\n(688457, 26) (117419, 26) (118967, 26)\n(688457,) (117419,) (118967,)\n(688457,)\n"
    }
   ],
   "source": [
    "#Quick checking of data shapes to see if load was correct\n",
    "print(df_train.shape, df_val.shape, df_test.shape)\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n",
    "print(instance_weights_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "It seems that predicting for variable-length sequences with sample weights stretches the functionality of TF to its boundaries - we hit some bugs in the library here. Fitting the GRU thus requires some workarounds:\n",
    "\n",
    "## Fitting to variable-length time sequences\n",
    "The model.fit and model.predict functions (and all other related predict functions) do not work with variable-length sequences: it seems that Tensorflow attempts to convert all sequences to Tensor format first, which is impossible due to the varying length (each dimension must be constant in a Tensor) and raises an error. There does not seem any way to disable this easily. \n",
    "* For feeding sequences with a batch size of 1 without any zero-padding, we must use a custom sequence generator, that yields a single time series in one batch, including features & labels & (possibly) sample weigths.\n",
    "    * Note that our implementation also allows for bigger batches than size 0, with possibly zero padding. However, specifying a batch size of 1 results in no zero-padding.\n",
    "* The .predict function, and all related predict functions, try to convert the output of all batches to a single tensor after predicting. Thus, these functions result in an error when used on variable-length sequences, even when using a custom sequence generator!\n",
    "    * Workaround 1: Predict for every batch individually using a for-loop. \n",
    "        * This is very slow and results in excessive printing of warnings - TF warns you that you should perform vectorized computations and not use Python for-loops.\n",
    "    * Workaround 2: Predict with all samples (all time series for all patients) in a single batch. To do this, zero-pad every sequence to the longest sequence length, predict, prune the zero padding again, and finally flatten the predictions back to a 1D array.\n",
    "        * This seems to run extremely fast without warnings and is thus the approach of choice.\n",
    "    \n",
    "## Sample weigths + variable-length time sequences\n",
    "There seems to be a bug when using sample weights for cells that take sequences as input (such as the GRU): setting sample_weight_mode to \"temporal\" in model.compile, as recommended in the documentation, still only seems to result in the use of one sample weight per patient. \n",
    "* Workaround: use one sample weight per patient time sequence. As the sample weight is a constant for all timesteps in a sequence anyway, this should yield the same result (i.e. it corresponds to moving the sample weight constant from *inside* the summation over all timesteps in a sequence in the loss function to a just-once multiplication *outside* summing the loss of all timesteps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seq_train, y_seq_train, instance_class_weights_seq_train = to_seq(df_train,\n",
    "                                                                    'subject_id',\n",
    "                                                                     X_train,\n",
    "                                                                     y_train,\n",
    "                                                                     instance_class_weights_train)\n",
    "\n",
    "X_seq_val, y_seq_val = to_seq(df_val,\n",
    "                              'subject_id',\n",
    "                               X_val,\n",
    "                               y_val)                                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1691 362\n1691\n1691 362\n"
    }
   ],
   "source": [
    "#Brief check: inspect some shapes of arrays\n",
    "print(len(X_seq_train), len(X_seq_val))\n",
    "print(len(instance_class_weights_seq_train))\n",
    "print(len(y_seq_train), len(y_seq_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_gru(input_shape):\n",
    "    \"\"\"\n",
    "    Generate a random densely connected neural network & return the configuration + model.\n",
    "    The possible value ranges for the hyperparameters are as specified in the thesis\n",
    "        - they are hard-coded.\n",
    "    \n",
    "    Returns: n_layers, n_units_per_layer, dropouts, model\n",
    "    \"\"\"\n",
    "    #Choose number of layers & number of units per layer\n",
    "    n_layers = int(np.random.randint(1,3,1)[0])\n",
    "    n_units_per_layer, l1_reg_per_layer, l2_reg_per_layer = [], [], []\n",
    "    for i in range(n_layers):\n",
    "        n_units_per_layer.append(int(np.random.randint(2,21,1)[0]))\n",
    "\n",
    "    #Setup the DL model\n",
    "    dropouts = []\n",
    "    model = tf.keras.Sequential()\n",
    "    for i, n_units in enumerate(n_units_per_layer):\n",
    "        if (i==0):\n",
    "            model.add(tf.keras.layers.GRU(n_units,\n",
    "                                          input_shape=input_shape,\n",
    "                                          return_sequences=True))\n",
    "        else:\n",
    "            #Add possible dropout and the dense layer with the random number of units\n",
    "            dropout_rate = np.random.uniform(0, 0.1)\n",
    "            dropouts.append(dropout_rate)\n",
    "            model.add(tf.keras.layers.GRU(n_units, return_sequences=True, dropout=dropout_rate))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid')) #Add the output layer, which always has 1 hidden unit and sigmoid output\n",
    "\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.AUC(curve='ROC', name='ROC_AUC')],\n",
    "                 )#sample_weight_mode='temporal')\n",
    "    \n",
    "    return n_layers, n_units_per_layer, dropouts, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the GRU with all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Set the results to be stored as raw Python types, otherwise we get issues w/ JSON writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "results = {}\n",
    "filenr=1 #Alter filenames sometimes such that we have restore points in case the data gets corrupted\n",
    "iteration = 0\n",
    "\n",
    "#Use a batch size of 1 to avoid excessive zero-padding and an excessive amount of extra data points to fit the model to\n",
    "train_gen = Sequence_generator(X_seq_train, y_seq_train, batch_size=1, sample_weight=instance_class_weights_seq_train)\n",
    "val_gen = Sequence_generator(X_seq_val, y_seq_val, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 718s 425ms/step - loss: 0.0061 - ROC_AUC: 0.7417 - val_loss: 0.6499 - val_ROC_AUC: 0.7741\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 750s 443ms/step - loss: 0.0048 - ROC_AUC: 0.7544 - val_loss: 0.7639 - val_ROC_AUC: 0.7586\n",
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 187s 111ms/step - loss: 0.0057 - ROC_AUC: 0.7134 - val_loss: 0.8136 - val_ROC_AUC: 0.7732\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 296s 175ms/step - loss: 0.0045 - ROC_AUC: 0.7620 - val_loss: 0.7359 - val_ROC_AUC: 0.7789\n",
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 280s 166ms/step - loss: 0.0078 - ROC_AUC: 0.6584 - val_loss: 0.7899 - val_ROC_AUC: 0.7441\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 267s 158ms/step - loss: 0.0055 - ROC_AUC: 0.7333 - val_loss: 0.8644 - val_ROC_AUC: 0.7669\n",
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 222s 132ms/step - loss: 0.0057 - ROC_AUC: 0.7302 - val_loss: 0.8441 - val_ROC_AUC: 0.7711\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 376s 222ms/step - loss: 0.0045 - ROC_AUC: 0.7574 - val_loss: 0.8632 - val_ROC_AUC: 0.7818\n",
      "5\n",
      "Epoch 1/100\n",
      " 830/1691 [=============>................] - ETA: 3:24 - loss: 0.0077 - ROC_AUC: 0.7159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "E0525 15:45:49.082839 19588 ultratb.py:152] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-b1d94ecf6662>\", line 28, in <module>\n",
      "    min_delta=0.05)]) #Stricter early stopping criteria due to more expensive models\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 66, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 848, in fit\n",
      "    tmp_logs = train_function(iterator)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 580, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 611, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2420, in __call__\n",
      "    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1665, in _filtered_call\n",
      "    self.captured_inputs)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1746, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 598, in call\n",
      "    ctx=ctx)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 60, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\KevinReijnders\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Automated tuning - stop this manually after your time budget has run out.\n",
    "while(True):\n",
    "    #Update iteration & file number\n",
    "    iteration += 1\n",
    "    if (iteration%5 ==0):\n",
    "        print(iteration)\n",
    "        filenr += 1\n",
    "    \n",
    "    #store start time of the fit & set random seed\n",
    "    start_time = time.time()\n",
    "    np.random.seed(iteration)\n",
    "    \n",
    "    #Create a randomized DNN & fit it to the data\n",
    "    n_layers, n_units_per_layer, dropouts, model = generate_random_gru(input_shape=(None, 26))\n",
    "\n",
    "    #Instantiate generators with batch size of 1 (to avoid excessive zero-padding due to some long sequences)\n",
    "    train_gen = Sequence_generator(X_seq_train, y_seq_train, batch_size=1, sample_weight=instance_class_weights_seq_train)\n",
    "    val_gen = Sequence_generator(X_seq_val, y_seq_val, batch_size=1)\n",
    "    model.fit(train_gen,\n",
    "              validation_data=val_gen,\n",
    "              epochs=100,\n",
    "              verbose=1,\n",
    "              callbacks= [tf.keras.callbacks.EarlyStopping(monitor='val_ROC_AUC',\n",
    "                                                           mode='max',\n",
    "                                                           patience=1, \n",
    "                                                           min_delta=0.05)]) #Stricter early stopping criteria due to more expensive models\n",
    "\n",
    "    #Compute performance using the workaround\n",
    "    val_gen = Sequence_generator(X_seq_val, y_seq_val, batch_size=len(X_seq_val)) #Create generator\n",
    "    y_score_seq = model.predict(val_gen) #Predict for all (padded) sequences\n",
    "    seq_lengths = [X_seq_val[i].shape[0] for i in range(len(X_seq_val))] #Prune the padding\n",
    "    y_score = np.vstack([y_score_seq[i][:seq_lengths[i]] for i in range(y_score_seq.shape[0])]) #Flatten the labels again\n",
    "    roc_auc = roc_auc_score(y_val, y_score)\n",
    "    auk = auk_score(y_val, y_score)\n",
    "\n",
    "    #Store the configuration & output (to raw python types, otherwise issues w/ writing JSON)\n",
    "    results[iteration] = {\n",
    "        'n_layers': n_layers,\n",
    "        'n_units_per_layer': n_units_per_layer,\n",
    "        'dropout_rate_per_layer': dropouts,\n",
    "        'roc_auc': roc_auc,\n",
    "        'auk': auk,\n",
    "        'fitting_time (minutes)': (time.time() - start_time)/60\n",
    "    }\n",
    "\n",
    "    # with open(os.path.join(data_base_path, 'model_tuning', 'GRU-all_feats-results-{}.json'.format(filenr)), 'w') as f:\n",
    "    #     json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the GRU with the features of the best PFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Set the results to be stored as raw Python types, otherwise we get issues w/ JSON writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the features from the best PFS configuration\n",
    "with open(os.path.join(data_base_path, 'model_tuning', 'Best-PFS-config.json'), 'r') as f:\n",
    "    pfs_config = json.load(f)\n",
    "indices_sel_features = pfs_config['feature_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alter sequences such that they only have the features selected in the PFS\n",
    "X_seq_new = []\n",
    "for X_seq in X_seq_train:\n",
    "    X_seq_new.append(\n",
    "        X_seq[:,indices_sel_features]\n",
    "    )\n",
    "X_seq_train = np.array(X_seq_new)\n",
    "\n",
    "X_seq_new = []\n",
    "for X_seq in X_seq_val:\n",
    "    X_seq_new.append(\n",
    "        X_seq[:,indices_sel_features]\n",
    "    )\n",
    "X_seq_val = np.array(X_seq_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "results = {}\n",
    "filenr=1 #Alter filenames sometimes such that we have restore points in case the data gets corrupted\n",
    "iteration = 0\n",
    "\n",
    "#Use a batch size of 1 to avoid excessive zero-padding and an excessive amount of extra data points to fit the model to\n",
    "train_gen = Sequence_generator(X_seq_train, y_seq_train, batch_size=1, sample_weight=instance_class_weights_seq_train)\n",
    "val_gen = Sequence_generator(X_seq_val, y_seq_val, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 705s 417ms/step - loss: 0.0080 - ROC_AUC: 0.6286 - val_loss: 1.2859 - val_ROC_AUC: 0.6660\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 805s 476ms/step - loss: 0.0068 - ROC_AUC: 0.6846 - val_loss: 0.9504 - val_ROC_AUC: 0.6687\n",
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 807s 477ms/step - loss: 0.0084 - ROC_AUC: 0.6271 - val_loss: 1.2624 - val_ROC_AUC: 0.7079\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 843s 499ms/step - loss: 0.0073 - ROC_AUC: 0.6905 - val_loss: 1.4178 - val_ROC_AUC: 0.7088\n",
      "Epoch 1/100\n",
      "1691/1691 [==============================] - 801s 473ms/step - loss: 0.0077 - ROC_AUC: 0.6697 - val_loss: 1.0840 - val_ROC_AUC: 0.6676\n",
      "Epoch 2/100\n",
      "1691/1691 [==============================] - 760s 449ms/step - loss: 0.0067 - ROC_AUC: 0.6926 - val_loss: 1.0115 - val_ROC_AUC: 0.6612\n",
      "Epoch 1/100\n",
      "  10/1691 [..............................] - ETA: 3:58 - loss: 0.0013 - ROC_AUC: 0.5901"
     ]
    }
   ],
   "source": [
    "#Automated tuning - stop this manually after your time budget has run out.\n",
    "while(True):\n",
    "    #Update iteration & file number\n",
    "    iteration += 1\n",
    "    if (iteration%5 ==0):\n",
    "        print(iteration)\n",
    "        filenr += 1\n",
    "    \n",
    "    #store start time of the fit & set random seed\n",
    "    start_time = time.time()\n",
    "    np.random.seed(iteration+500) #Different seeds than version with all features\n",
    "    \n",
    "    #Create a randomized DNN & fit it to the data\n",
    "    n_layers, n_units_per_layer, dropouts, model = generate_random_gru(input_shape=(None, len(indices_sel_features)))\n",
    "\n",
    "    #Instantiate generators with batch size of 1 (to avoid excessive zero-padding due to some long sequences)\n",
    "    train_gen = Sequence_generator(X_seq_train, y_seq_train, batch_size=1, sample_weight=instance_class_weights_seq_train)\n",
    "    val_gen = Sequence_generator(X_seq_val, y_seq_val, batch_size=1)\n",
    "    model.fit(train_gen,\n",
    "              validation_data=val_gen,\n",
    "              epochs=100,\n",
    "              verbose=1,\n",
    "              callbacks= [tf.keras.callbacks.EarlyStopping(monitor='val_ROC_AUC',\n",
    "                                                           mode='max',\n",
    "                                                           patience=1, \n",
    "                                                           min_delta=0.05)]) #Stricter early stopping criteria due to more expensive models\n",
    "\n",
    "    #Compute performance using the workaround\n",
    "    val_gen = Sequence_generator(X_seq_val, y_seq_val, batch_size=len(X_seq_val)) #Create generator\n",
    "    y_score_seq = model.predict(val_gen) #Predict for all (padded) sequences\n",
    "    seq_lengths = [X_seq_val[i].shape[0] for i in range(len(X_seq_val))] #Prune the padding\n",
    "    y_score = np.vstack([y_score_seq[i][:seq_lengths[i]] for i in range(y_score_seq.shape[0])]) #Flatten the labels again\n",
    "    roc_auc = roc_auc_score(y_val, y_score)\n",
    "    auk = auk_score(y_val, y_score)\n",
    "\n",
    "    #Store the configuration & output (to raw python types, otherwise issues w/ writing JSON)\n",
    "    results[iteration] = {\n",
    "        'n_layers': n_layers,\n",
    "        'n_units_per_layer': n_units_per_layer,\n",
    "        'dropout_rate_per_layer': dropouts,\n",
    "        'roc_auc': roc_auc,\n",
    "        'auk': auk,\n",
    "        'fitting_time (minutes)': (time.time() - start_time)/60\n",
    "    }\n",
    "\n",
    "    # with open(os.path.join(data_base_path, 'model_tuning', 'GRU-pfs_feats-results-{}.json'.format(filenr)), 'w') as f:\n",
    "    #     json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick analysis of the results & storing the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_json(os.path.join(data_base_path, 'model_tuning', 'GRU-all_feats-results-1.json'),\n",
    "                      orient='index')\n",
    "df_pfs = pd.read_json(os.path.join(data_base_path, 'model_tuning', 'GRU-pfs_feats-results-1.json'),\n",
    "                      orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_units_per_layer</th>\n",
       "      <th>dropout_rate_per_layer</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>auk</th>\n",
       "      <th>fitting_time (minutes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.781861</td>\n",
       "      <td>0.141310</td>\n",
       "      <td>10.055467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.778956</td>\n",
       "      <td>0.139485</td>\n",
       "      <td>8.099269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.767229</td>\n",
       "      <td>0.133890</td>\n",
       "      <td>9.181591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>[0.093255735933865]</td>\n",
       "      <td>0.758658</td>\n",
       "      <td>0.129112</td>\n",
       "      <td>24.553569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_layers n_units_per_layer dropout_rate_per_layer   roc_auc       auk  \\\n",
       "4         1              [16]                     []  0.781861  0.141310   \n",
       "2         1              [17]                     []  0.778956  0.139485   \n",
       "3         1               [5]                     []  0.767229  0.133890   \n",
       "1         2          [13, 14]    [0.093255735933865]  0.758658  0.129112   \n",
       "\n",
       "   fitting_time (minutes)  \n",
       "4               10.055467  \n",
       "2                8.099269  \n",
       "3                9.181591  \n",
       "1               24.553569  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.sort_values('roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_layers</th>\n",
       "      <th>n_units_per_layer</th>\n",
       "      <th>dropout_rate_per_layer</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>auk</th>\n",
       "      <th>fitting_time (minutes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[2, 15]</td>\n",
       "      <td>[0.034833486428848]</td>\n",
       "      <td>0.709630</td>\n",
       "      <td>0.100522</td>\n",
       "      <td>27.584601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[9, 17]</td>\n",
       "      <td>[0.00587862674409]</td>\n",
       "      <td>0.668772</td>\n",
       "      <td>0.081022</td>\n",
       "      <td>25.244659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[8, 9]</td>\n",
       "      <td>[0.090385537299124]</td>\n",
       "      <td>0.661141</td>\n",
       "      <td>0.079320</td>\n",
       "      <td>26.086430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_layers n_units_per_layer dropout_rate_per_layer   roc_auc       auk  \\\n",
       "2         2           [2, 15]    [0.034833486428848]  0.709630  0.100522   \n",
       "1         2           [9, 17]     [0.00587862674409]  0.668772  0.081022   \n",
       "3         2            [8, 9]    [0.090385537299124]  0.661141  0.079320   \n",
       "\n",
       "   fitting_time (minutes)  \n",
       "2               27.584601  \n",
       "1               25.244659  \n",
       "3               26.086430  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pfs.sort_values('roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export best configs the hyperparameters of the best GRU models\n",
    "# with open(os.path.join(data_base_path, 'model_tuning', 'Best-GRU-configs.json'), 'w') as f:\n",
    "#     best_dnn_config = {\n",
    "#         1: {\n",
    "#             'features': 'all',\n",
    "#             'n_layers': 1,\n",
    "#             'n_units_per_layer': [16],\n",
    "#             'dropout_rates': [],\n",
    "#         },\n",
    "#         2: {\n",
    "#             'features': 'best_pfs',\n",
    "#             'n_layers': 2,\n",
    "#             'n_units_per_layer': [2,15],\n",
    "#             'dropout_rates': [0.034833486428848],\n",
    "#         },\n",
    "#     }\n",
    "#     json.dump(best_dnn_config, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}